---
title: "Statistics in Action - case study 1"
author: "Sebastien Moeller"
output:
  html_document:
    fig_height: 3
    fig_width: 8
    number_sections: no
    toc: no
  pdf_document:
    fig_height: 3
    fig_width: 8
    includes:
      before_body: macros.tex
    keep_tex: yes
    number_sections: no
    toc: no
---

```{r}
if (!require("pacman")) install.packages("pacman")

pacman::p_load(equivalence, tidyverse, ggplot2, dplyr, plyr, pwr)
```

# Introduction

The dataset <ttt>dataMON810_2018.csv</ttt> consists of several measurements made during a subchronic toxicity study concerning the MON810 maize.

Biochemical parameters reflecting most physiological functions were measured two times (week 5 and 14), in particular through serum and urine chemistry, and hematology. Organ weights were measured at week 14.

The main objective of this study is to evaluate possible GMO effects on these parameters.

# Single comparison

#### __(Q1)__ 
We consider the variable "CALCIUM".
```{r}
data <- read.csv('dataMON810_2018.csv')
```

##### a. Test if the mean level of calcium for period 2 is the same for males and females.  </br>**Hint:** plot first the data and justify the test(s) to use.
```{r}
# Filter the data was want and remove NA from variable
calciumA <- data %>% filter(period == 2) %>% select(CALCIUM, sex) %>% na.omit
# Calculate the sample means
calciumAMean <- aggregate(calciumA$CALCIUM  ~ calciumA$sex, FUN = 'mean')
colnames(calciumAMean) <- c('sex', 'CALCIUM')

# Plot the data
ggplot() + 
  geom_point(data = calciumA, aes(x = CALCIUM, y = sex, colour = sex, alpha = 0.5), show.legend = FALSE) +
  geom_point(data = calciumAMean, aes(x = CALCIUM, y = sex, color = sex, size = 4, alpha = 0.5), show.legend = FALSE)

# Let's take a look at the means
calciumAMean
```

Looking at the data we see that the `$CALCIUM$` means between male and female are close. Computing a p-value here is of interest to see if they are significantly different.

The hypotheses we are testing are as follow:
$$
H_0:\mu_{x} = \mu_{y} \space\text{ versus }\space H_1:\mu_{x} \neq\mu_{y}
$$

##### Let us look at the distribution of the observations
```{r}
calciumA <- ddply(calciumA, 'sex', transform, mean = mean(CALCIUM))

ggplot(data = calciumA, aes(x = CALCIUM, color = sex)) + geom_histogram(bins = 25) + 
  geom_vline(aes(xintercept = mean), linetype = 3) +
  facet_grid(~sex) + theme_bw()
```

The histograms seem to reveal a distribution not too far from normal. This allows us to apply the student t-test to compare the means as it assumes normallity.

##### Assuming equal variances
We can use the function `t.test`. Let $x$ and $y$ denote $males$ and $females$ respectively.

We run our first test assuming equal variances $(\sigma^2_x = \sigma^2_y)$. We select a 5% significance level and run the test.
```{r}
alpha <- 0.05
t.test((calciumA %>% filter(sex == 'M'))$CALCIUM, (calciumA %>% filter(sex == 'F'))$CALCIUM, conf.level = 1 - alpha, var.equal = TRUE)
```

Under the assumption that the two sexes have equal variances, we find a low `p-value < 2.2e-16` and thus __reject the null hypothesis__ that $\mu_x = \mu_y$.

##### F-test for equal variances
As stated, the previous t-test assumed that the two populations have equal variances. It is unreasonable to make this assumption without an additional test. An F-test is used to test if the variances of two populations are equal. We will perform a two tailed test to see if our previous assumption was valid or not.

For the F-test, our hypotheses are as follow:
$H_0: \sigma_x = \sigma_y \space\text{versus}\space H_1:\sigma_x \neq \sigma_y$
```{r}
test <- var.test((calciumA %>% filter(sex == 'M'))$CALCIUM, (calciumA %>% filter(sex == 'F'))$CALCIUM, conf.level = 1 - alpha, alternative = 'two.sided')
test
# Do we reject the null hypothesis?
test$p.val < 0.05
```

Our intuition was correct, the true ratio of variances $\frac{\sigma_x}{\sigma_y} \neq 1$. Thus we __reject the null hypothesis__.

##### Assuming different variances
Assuming equal variances between the two groups has been disputed.
```{r}
aggregate(calciumA$CALCIUM  ~ calciumA$sex, FUN = 'sd')
dim(calciumA[calciumA$sex == 'F',])[1]
dim(calciumA[calciumA$sex == 'M',])[1]
```

The sample data of size 90 for females and 97 for males have very different standard deviations. It is therefore important to run the t-test without the assumption of equal variances.
```{r}
t.test((calciumA %>% filter(sex == 'M'))$CALCIUM, (calciumA %>% filter(sex == 'F'))$CALCIUM, conf.level = 1 - alpha, var.equal = FALSE)
```

Our new t-test also __rejects the null hypothesis__ that the two groups share the same mean displaying a `p-value = 3.455e-15`.

##### Conclusion
We can safely conclude that the two sexes do indeed have different means by the means of a t-test without equal variances.

##### b. Test for the males if the mean level of calcium is the same for period 1 and period 2.
```{r}
# Filter the data was want and remove NA from variable
calciumB <- data %>% filter(sex == 'M') %>% select(period, CALCIUM) %>% na.omit
calciumB$period <- as.factor(calciumB$period)

calciumBMean <- aggregate(calciumB$CALCIUM  ~ calciumB$period, FUN = 'mean')
colnames(calciumBMean) <- c('period', 'CALCIUM')

# Plot the data
ggplot() + 
  geom_point(data = calciumB, aes(x = CALCIUM, y = period, colour = period, alpha = 0.5), show.legend = FALSE) +
  geom_point(data = calciumBMean, aes(x = CALCIUM, y = period, color = period, size = 4, alpha = 0.5), show.legend = FALSE)

# Let's take a look at the means
calciumBMean
```

```{r}
calciumB <- ddply(calciumB, 'period', transform, mean = mean(CALCIUM))

ggplot(data = calciumB, aes(x = CALCIUM, color = period)) + geom_histogram(bins = 20) + 
  geom_vline(aes(xintercept = mean), linetype = 3) +
  facet_grid(~period) + theme_bw()
```

As with the previous question, the data does seem to follow a normal distribution although it could be argued otherwise. For now, we will run our tests on the data using the t-test. We will consider other options in the later sections.

##### F-test for equal variances
As stated, the previous t-test assumed that the two populations have equal variances. An F-test is used to test if the variances of two populations are equal. We will perform a two tailed test to see if our previous assumption was valid or incorrect.

For the F-test, our hypotheses are as follow:
$H_0: \sigma_x = \sigma_y \space\text{versus}\space H_1:\sigma_x \neq \sigma_y$
```{r}
test <- var.test((calciumB %>% filter(period == 1))$CALCIUM, (calciumB %>% filter(period == 2))$CALCIUM, conf.level = 1 - alpha, alternative = 'two.sided')
test
# Do we reject the null hypothesis
test$p.val < 0.05
```

Our intuition was correct, the true ratio of variances $\frac{\sigma_x}{\sigma_y} \neq 1$. Thus we __reject the null hypothesis__.

##### Assuming different variances
Assuming equal variances between the two groups has been disputed.
```{r}
aggregate(calciumB$CALCIUM  ~ calciumB$period, FUN = 'sd')
```

```{r}
dim(filter(calciumB, period == 1))[1]
dim(filter(calciumB, period == 2))[1]
```

The sample data of size 98 for period 1, and 97 for period 2 have very different standard deviations. It is therefore important to run the t-test without the assumption of equal variances especially because we rejected the F-test's null hypothesis.
```{r}
test <- t.test((calciumB %>% filter(period == 1))$CALCIUM, (calciumB %>% filter(period == 2))$CALCIUM, conf.level = 1 - alpha, var.equal = FALSE)
test
# Do we reject the null hypothesis?
test$p.value < 0.05
```

Our new t-test also __rejects the null hypothesis__ that the two groups share the same mean displaying a `p-value = 3.113e-10`.

##### Conclusion
We can safely conclude that the male population between the two periods do indeed have different means.

##### c. Test for the males if the mean level of calcium for period 2 is the same for the control group and the MON810 group.
```{r}
# Filter the data was want and remove NA from variable
calciumC <- data %>% filter(sex == 'M') %>% filter(period == 2) %>% select(regimen, CALCIUM) %>% filter(regimen %in% c('MON810', 'control')) %>% na.omit
calciumC$regimen <- as.factor(calciumC$regimen)

calciumCMean <- aggregate(calciumC$CALCIUM  ~ calciumC$regimen, FUN = 'mean')
colnames(calciumCMean) <- c('regimen', 'CALCIUM')

# Plot the data
ggplot() + 
  geom_point(data = calciumC, aes(x = CALCIUM, y = regimen, colour = regimen, alpha = 0.5), show.legend = FALSE) +
  geom_point(data = calciumCMean, aes(x = CALCIUM, y = regimen, color = regimen, size = 4, alpha = 0.5), show.legend = FALSE)

# Let's take a look at the means
calciumCMean
```

```{r}
calciumC <- ddply(calciumC, 'regimen', transform, mean = mean(CALCIUM))

ggplot(data = calciumC, aes(x = CALCIUM, color = regimen)) + geom_histogram(bins = 15) + 
  geom_vline(aes(xintercept = mean), linetype = 3) +
  facet_grid(~regimen) + theme_bw()
```

```{r}
# Number of observations from the control group
dim(filter(calciumC, regimen == 'control'))[1]
# Number of observations frmo the MON810 group
dim(filter(calciumC, regimen == 'MON810'))[1]
```

The histogram is a little worrying as the data seems unlikely to follow a normal distribution. As the sample size for the groups is 20 for control and 19 for MON810 which are rather low, it is harder to grasp the distribution via the histogram.

##### Wilcox Test
The advantage with Wilcoxon Signed Rank Test is that it neither depends on the form of the parent distribution nor on its parameters. It does not require any assumptions about the shape of the distribution.

For this reason, this test is often used as an alternative to the t-test whenever the population cannot be assumed to be normally distributed. Even if the normality assumption holds, it has been shown that the efficiency of this test compared to t-test is almost 95%.
```{r, warning = FALSE}
test <- wilcox.test((calciumC %>% filter(regimen == 'control'))$CALCIUM, (calciumC %>% filter(regimen == 'MON810'))$CALCIUM, alternative = 'two.sided', conf.level=1-0.05)
test
# Do we reject the null hypothesis
test$p.value > 0.05
```
Our new wilcox-test  __rejects the alternate hypothesis__ that the two groups do not share the same mean displaying a very significant `p-value = 0.694`.

Checking this resut with the t-test we used in the previous questions, we get the following result:
```{r}
t.test((calciumC %>% filter(regimen == 'control'))$CALCIUM, (calciumC %>% filter(regimen == 'MON810'))$CALCIUM, conf.level = 1 - alpha, var.equal = FALSE)
```

Our t-test *also* __rejects the alternate hypothesis__ that the two groups do not share the same mean displaying a very significant `p-value = 0.4466`.

##### Conclusion
We conclude that the two groups do not have significantly different means. We were able to discard our assumption for normality from the t-test by applying the wilcox test instead. This test appears to be more appropriate as our data has unusual distributions.

##### d. What is the probability to detect a difference of 1 sd (one standard deviation) 

*i)* with only 10 animals per group?
We can check this by running the code in the function pwr.t.test
```{r}
pwr.t.test(n = 10, d = 1, type = "two.sample", alternative = "two.sided", sig.level = alpha)[[4]]*100
```
So the probability of detecting 1 sd difference with only 10 animals per group is 56.20%

*ii)* with 20 animals? 
Next we try the same but change the sample size to 20 animals per group
```{r}
pwr.t.test(n = 20, d = 1, type = "two.sample", alternative = "two.sided", sig.level = alpha)[[4]]*100
```
The probability of detecting 1 sd difference with only 20 animals per group is 86.90%

*iii)* How can we ensure to detect such difference with a probability of 80%?
For this we fill in the power function and set 
```{r}
pwr.t.test(power = 0.8, d = 1, sig.level = alpha)
```
Only by having at least `n = 17` observations can we detect a difference of 1 standard deviation with at least an 80% accuracy.

##### e. Test for the males if the mean levels of calcium for period 2 of the `control` and `MON810` groups* are equivalent. The equivalence limits will be defined using the 6 reference groups as 
```{r}
# Filter the relevant data
calciumE <- data %>% filter(sex == 'M', period == 2, regimen != 'control', regimen != 'MON810') %>% select(regimen, CALCIUM) %>% na.omit
calciumE$regimen <- as.factor(calciumE$regimen)

# Calculate the mean of each regiem
calciumEMean <- aggregate(calciumE$CALCIUM  ~ calciumE$regimen, FUN = 'mean')
colnames(calciumEMean) <- c('regimen', 'CALCIUM')
calciumEMean
```

*i)* one standard deviation of the 6 reference means,
```{r}
# The size of our confidence interval is given by a deviation from the mean in either direction of:
sd(calciumEMean$CALCIUM)

# The probability of observing a deviation of this size
pt(q = -sd(calciumEMean$CALCIUM), df = dim(calciumE)[1]-6)*2*100
```

The result shows that we have a probability of `42.30%` of observing one standard deviation of the 6 reference means given all observations.

Our degrees of freedom is given by the number of observations minus the number of separate sets we calculated the means from: `df = 58 - 6 = 52`

```{r}
# Calculate the p-value
test <- tost((calciumC %>% filter(regimen == 'control'))[,2], (calciumC %>% filter(regimen == 'MON810'))[,2], alpha = 0.05, epsilon = sd(calciumEMean$CALCIUM))
test
test$tost.p.value
```

The tost test can be interpreted as a regular two sided test checking if the means are within a range of $\pm\space\epsilon$. As the p-value is so high, we __reject the alternate hypothesis__ that the two sets are not equivalent. Indeed, under these conditions we argue that they __are equivalent__.

*ii)* two standard deviations of the 6 reference means.
```{r}
# The probability of observing a deviation of twice this size
pt(q = -2*sd(calciumEMean$CALCIUM), df = dim(calciumE)[1]-6)*2*100
```

Similarly, the probability of observing two standard deviations from the mean given our data is `11.75%` with `df = 52`
```{r}
# Calculate the p-value
test <- tost((calciumC %>% filter(regimen == 'control'))[,2], (calciumC %>% filter(regimen == 'MON810'))[,2], alpha = 0.05, epsilon = 2*sd(calciumEMean$CALCIUM))
test
test$tost.p.value
```

The tost test can be interpreted as a regular two sided test checking if the means are within a range of $\pm\space\epsilon$. As the p-value is so high, we __reject the alternate hypothesis__ that the two sets are not equivalent. Indeed, under these conditions we argue that they __are equivalent__.
   
##### f. Summarize and comment these results.

a) level of calcium for period 2 for males and females
- Our F-test conculded that the two sets have distinct variances.
$\sigma_x\neq\sigma_y$
- The T-test then rejected the null hypothesis arguing that the means are different between the two sets.
$\mu_x\neq\mu_y$

b) level of calcium for males in period 1 and period 2
- Our F-test conculded that the two sets have distinct variances.
$\sigma_x\neq\sigma_y$
- The T-test then rejected the null hypothesis arguing that the means are different between the two sets.
$\mu_x\neq\mu_y$

c) level of calcium for males in period 2 is the same for the control and MON810 group
- The wilcox test rejected the alternate hypothesis, arguing that the means are shared between the two sets
$\mu_x=\mu_y$

We switched from performing the t-test to the wilcox test due to the distribution of our sample data. The histogram did not appear to follow a normal distribution and thus we dropped the assumption of normality by using the wilcox test instead.

d)
We have a 56.20% power with `n = 10` observations
We have a 86.89% power with `n = 20` observations.
Only by having at least `n = 17` observations can we detect a difference of 1 standard deviation with at least an 80% accuracy.


e)
the two means __are equivalent__ at 1 standard deviation
the two means __are equivalent__ at 2 standard deviations


#### __(Q2)__ Do the same analysis with the variable "DIRBILI" (direct bilirubin)
```{r, echo = FALSE}
questionA_wilcox <- function(variable, alpha, m){
  # Filter the data was want and remove NA from variable
  dataNew <- data %>% filter(period == 2) %>% select(sex, variable) %>% na.omit
  
  # Check if the the two groups have at least one observation
  if(dim((dataNew %>% filter(sex == 'M')))[1] > 0 && dim(dataNew %>% filter(sex == 'F'))[1] > 0){
    # Wilcox p-value
    return(wilcox.test((dataNew %>% filter(sex == 'M'))[,2], (dataNew %>% filter(sex == 'F'))[,2], alternative = 'two.sided', conf.level=1-alpha/m))
  }
  else{
    return(NA)
  }
}

questionB_wilcox <- function(variable, alpha, m){
  # Filter the variable for males in period 1 and 2
  dataNew <- data %>% filter(sex == 'M') %>% select(period, variable) %>% na.omit
  
  # Check if the the two groups have at least one observation
  if(dim(dataNew %>% filter(period == 2))[1] > 0 && dim(dataNew %>% filter(period == 1))[1] > 0){
    # Wilcox p-value
    return(wilcox.test((dataNew %>% filter(period == 1))[,2], (dataNew %>% filter(period == 2))[,2], alternative = 'two.sided', conf.level=1-alpha/m))
  }
  else{
    return(NA)
  }
}

questionC_wilcox <- function(variable, alpha, m){
  # Filter the data was want and remove NA from variable
  dataNew <- data %>% filter(sex == 'M') %>% filter(period == 2) %>% select(regimen, variable) %>% filter(regimen %in% c('MON810', 'control')) %>% na.omit
  
  # Check if the the two groups have at least one observation
  if(dim((dataNew %>% filter(regimen == 'control')))[1] > 0 && dim(dataNew %>% filter(regimen == 'MON810'))[1] > 0){
    # Wilcox p-value
    return(wilcox.test((dataNew %>% filter(regimen == 'control'))[,2], (dataNew %>% filter(regimen == 'MON810'))[,2], alternative = 'two.sided', conf.level=1-alpha/m))
  }
  else{
    return(NA)
  }
}
```

We consider the variable "DIRBILI".

##### a. Test if the mean level of DIRBILI for period 2 is the same for males and females.
```{r}
# Filter the data was want and remove NA from variable
dirbiliA <- data %>% filter(period == 2) %>% select(DIRBILI, sex) %>% na.omit

# Calculate the sample means
dirbiliAMean <- aggregate(dirbiliA$DIRBILI  ~ dirbiliA$sex, FUN = 'mean')
colnames(dirbiliAMean) <- c('sex', 'DIRBILI')

# Plot the data
ggplot() + 
  geom_point(data = dirbiliA, aes(x = DIRBILI, y = sex, colour = sex, alpha = 0.5), show.legend = FALSE) +
  geom_point(data = dirbiliAMean, aes(x = DIRBILI, y = sex, color = sex, size = 4, alpha = 0.5), show.legend = FALSE)
```

```{r}
dirbiliA <- ddply(dirbiliA, 'sex', transform, mean = mean(DIRBILI))

ggplot(data = dirbiliA, aes(x = DIRBILI, color = sex)) + geom_histogram(bins = 20) + 
  geom_vline(aes(xintercept = mean), linetype = 3) +
  facet_grid(~sex) + theme_bw()
```


This data seems to be discrete, having a value of 0.100 or 0.001 in period 2.
```{r}
unique(dirbiliA)
```

```{r}
# Let's take a look at the means by sex
dirbiliAMean
```

We will make use of the Chi-Square test to test for independence of `gender` for `DIRBILI`. If gender is independent then the two sexes share the same mean, otherwise they have distinct means.

For the Chi-square test to function in R we need to transform the data into a contingency table following the form:
```{r}
table(dirbiliA)
```

We set `correction = FALSE` as correction for continuity adjusts the formula for Pearson's chi-squared test. It subtracts 0.5 from the difference between each observed value and its expected value in a 2 ? 2 contingency table. This reduces the chi-squared value obtained and thus increases its p-value. This formula is chiefly used when at least one cell of the table has an expected count smaller than 5. As Yates' correction also tends to overcorrect, and we know that we have significantly more than 5 counts per group we choose not to perform the correction.

The Chi-square test is performed as follows:
$\chi^2=\sum_{i = 1}^N\frac{(O_i-E_i)^2}{E_i}$

The df is given by a function of the contingency table: `df = (nrow - 1)(ncol - 1) = (1)(1) = 1`

$H_0: \mu_x\neq\mu_y\space\text{versus}\space H_1:\mu_x=\mu_y$
```{r}
chisq.test(table(dirbiliA[, 1:2]), correct = FALSE)
```

Our test returns `p-value = 0.5814` indicating that the two sexes DIRBILI values are not independent and actually share a common mean.

### IMPORTANT REMARK

The chi-square test is intended for categorical variables. Therefore it is unlikely the be applicable in our case where we are working with ordinal and intervaled data. This is why we must resort to the wilcox test.

```{r}
questionA_wilcox("DIRBILI", 0.05, 1)
questionA_wilcox("DIRBILI", 0.05, 1)$p.val
```

The wilcox is a useful approach as it does not assume anything about the distribution or parameters. As our observations consist of only __two__ values it is difficult to assume a continuous distribution. Wilcox works around this issue and calculates a p-value = `0.5835049`, similar to that of the chi square test and __rejects the alternative hypothesis__.

##### b. Test for the males if the mean level of DIRBILI is the same for period 1 and period 2.
```{r}
# Filter the data was want and remove NA from variable
dirbiliB <- data %>% select(DIRBILI, period) %>% na.omit
dirbiliB$period <- as.factor(dirbiliB$period)

# Calculate means by period
dirbiliBMean <- aggregate(dirbiliB$DIRBILI ~ dirbiliB$period, FUN = 'mean')
colnames(dirbiliBMean) <- c('period', 'DIRBILI')

# Plot the data
ggplot() +
  geom_point(data = dirbiliB, aes(x = DIRBILI, y = period, colour = period, alpha = 0.5), show.legend = FALSE) +
  geom_point(data = dirbiliBMean, aes(x = DIRBILI, y = period, color = period, size = 4, alpha = 0.5), show.legend = FALSE)
```

We immediately suspect that the two periods do not have independent means. Let us verify our suspicion with a Chi-square test with the same set-up as question a.
```{r}
table(dirbiliB)
```

### IMPORTANT REMARK

The chi-square test is intended for categorical variables. It is __not__ applicable in our case where we are working with ordinal and intervaled data with three levels. Although we return a result we cannot use it and must instead resort to the wilcox test.

```{r}
questionB_wilcox("DIRBILI", 0.05, 1)
questionB_wilcox("DIRBILI", 0.05, 1)$p.val
```

The wilcox is a useful approach as it does not assume anything about the distribution or parameters. As our observations consist of only __three__ values it is difficult to assume a continuous distribution. Wilcox works around this issue and calculates a low p-value much lower than our 5% cutoff. We find a `p-value = 4.819985e-11` and thus __reject the null hypothesis__. The two sets have distinct means.

##### c. Test for the males if the mean level of DIRBILI for period 2 is the same for the control group and the MON810 group.
```{r}
# Filter the data
dirbiliC <- data %>% filter(sex == 'M', period == 2) %>% select(regimen, DIRBILI) %>% filter(regimen %in% c('MON810', 'control')) %>% na.omit

# Calculate the means per regimen
dirbiliCMean <- aggregate(dirbiliC$DIRBILI ~ dirbiliC$regimen, FUN = 'mean')
colnames(dirbiliCMean) <- c('regimen', 'DIRBILI')

# Plot the data
ggplot() + 
  geom_point(data = dirbiliC, aes(x = DIRBILI, y = regimen, colour = regimen, alpha = 0.5), show.legend = FALSE) +
  geom_point(data = dirbiliCMean, aes(x = DIRBILI, y = regimen, color = regimen, size = 4, alpha = 0.5), show.legend = FALSE)
```

The plot seems to imply equal means between the `control` and `MON810` regimens.
```{r}
table(dirbiliC)[1:2,]
```

The contingency table shows that the two regiems have exactly the same frequency of each value. We expect a `p-value = 1`. As these are random variables, the true p-value is likely to be very close to 1
```{r}
chisq.test(table(dirbiliC)[1:2,])
```

With a `p-value = 1` we reject the alternative hypothesis. The two regimens `contol` and `MON810` share the same mean.

### IMPORTANT REMARK

The chi-square test is intended for categorical variables. Therefore it is unlikely the be applicable in our case where we are working with ordinal and intervaled data. This is why we must resort to the wilcox test.

###### Wilcox alternative
```{r, warning = FALSE}
questionC_wilcox("DIRBILI", 0.05, 1)
questionC_wilcox("DIRBILI", 0.05, 1)$p.val
```

The wilcox is a useful approach as it does not assume anything about the distribution or parameters. As our observations consist of only two values but their ordinality and interval matter, it is difficult to assume a categorical distribution. Wilcox works around this issue and calculates a p-value equal to the chi square test of 1.

##### d. What is the probability to detect a difference of 1 sd (one standard deviation)

As we are testing two proportions we will need the pwr.2p.test to compute the power.

*i)* with only 10 animals per group? 
```{r}
pwr.2p.test(n = 10, h = 1, alternative = "two.sided", sig.level = 0.05)
```

We have a 60.88% power with `n = 10` observations.

*ii)* with 20 animal? 
```{r}
pwr.2p.test(n = 20, h = 1, alternative = "two.sided", sig.level = 0.05)
```

We have a 88.54% power with `n = 20` observations.

*iii)* How can we ensure to detect such difference with a probability of 80%?
```{r}
pwr.2p.test(power = 0.80, h = 1, alternative = "two.sided", sig.level = 0.05)
```
Only by having at least `n = 16` observations can we detect a difference of 1 standard deviation with at least an 80% accuracy.

##### e. Test for the males if the mean levels of calcium for period 2 of the control group and the MON810 are equivalent. The equivalence limits will be defined using the 6 reference groups as
```{r}
# Filter the data
dirbiliE <- data %>% filter(sex == 'M', period == 2, regimen != 'control', regimen != 'MON810') %>% select(regimen, DIRBILI) %>% na.omit
dirbiliE$regimen <- as.factor(dirbiliE$regimen)

# Calculate the mean of each regiem
dirbiliEMean <- aggregate(dirbiliE$DIRBILI  ~ dirbiliE$regimen, FUN = 'mean')
colnames(dirbiliEMean) <- c('regimen', 'DIRBILI')
dirbiliEMean
```

*i)* one standard deviation of the 6 reference means
```{r}
# The size of our confidence interval is given by a deviation from the mean in either direction of:
sd(dirbiliEMean$DIRBILI)

# The probability of observing a deviation of this size
pt(q = -sd(dirbiliEMean$DIRBILI), df = dim(dirbiliE)[1]-dim(dirbiliEMean)[1])*2*100
```

We find that the probability of observing one standard deviation is `99.18%`.
```{r}
# Calculate the p-value
test <- tost((dirbiliC %>% filter(regimen == 'control'))[,2], (dirbiliC %>% filter(regimen == 'MON810'))[,2], alpha = 0.05, epsilon = sd(dirbiliEMean$DIRBILI))
test
# p-value
test$tost.p.value
```
The output can be interpreted similarly to a standard hypothesis test, therefore from the p-value we conclude that the two means __are equivalent__, we __reject the alternative hypothesis__.

*ii)* two standard deviations of the 6 reference means.
```{r}
# The probability of observing a deviation of twice this size
pt(q = -2*sd(dirbiliEMean$DIRBILI), df = dim(dirbiliE)[1]-dim(dirbiliEMean)[1])*2*100
```

We find that the probability of observing two standard deviations is `98.35%`.
```{r}
# Calculate the p-value
test <- tost((dirbiliC %>% filter(regimen == 'control'))[,2], (dirbiliC %>% filter(regimen == 'MON810'))[,2], alpha = 0.05, epsilon = 2*sd(dirbiliEMean$DIRBILI))
test
# p-value
test$tost.p.value
```
The output can be interpreted similarly to a standard hypothesis test, therefore from the p-value > 0.05 we __reject the alternative hypothesis__ and argue that the two means __are equivalent__.

##### f. Summarize and comment these results.

a) level of dirbili for period 2 for males and females
- The Chi-Square test rejected the __alternate hypothesis__, arguing that the means are shared between the two sets.
- The wilcox test rejected the __alternate hypothesis__, arguing that the means are shared between the two sets.
$\mu_x=\mu_y$

b) level of dirbili for males in period 1 and period 2
- The Chi-Square test rejected the __null hypothesis__, arguing that the means are shared between the two sets.
- The wilcox test rejected the __null hypothesis__, arguing that the means are shared between the two sets.
$\mu_x\neq\mu_y$

c) level of dirbili for males in period 2 is the same for the control and MON810 group
- The wilcox test rejected the __alternate hypothesis__, arguing that the means are shared between the two sets
$\mu_x=\mu_y$

d) What is the probability to detect a difference of 1 sd (one standard deviation)
We have a 60.88% power with `n = 10` observations.
We have a 88.54% power with `n = 20` observations.
Only by having at least `n = 16` observations can we detect a difference of 1 standard deviation with at least an 80% accuracy.

e) 
the two means __are equivalent__ at 1 standard deviation
the two means __are equivalent__ at 2 standard deviations

# Multiple comparisons
#### __(Q1)__
Redo the three tests of the previous section (questions a., b. and c.) for now comparing  the means of all the quantitative variables (see the annex 5 of the ANSES report <ttt>BIOT2009sa0285Ra.pdf</ttt> to know the type of each variable).

##### a. mean level for period 2 is the same for males and females.
```{r}
questionA_ttest <- function(variable, alpha, m){
  # Filter the data was want and remove NA from variable
  dataNew <- data %>% filter(period == 2) %>% select(sex, variable) %>% na.omit
  
  # Check if the the two groups have at least one observation
  if(dim((dataNew %>% filter(sex == 'M')))[1] > 0 && dim(dataNew %>% filter(sex == 'F'))[1] > 0){
    # F-test
    pVal <- var.test((dataNew %>% filter(sex == 'M'))[,2], (dataNew %>% filter(sex == 'F'))[,2], conf.level = 1 - alpha, alternative = 'two.sided')$p.val
    
    # Check F-test result
    varEqual <- pVal > alpha
    
    # Perform the t-test
    return(t.test((dataNew %>% filter(sex == 'M'))[,2], (dataNew %>% filter(sex == 'F'))[,2], conf.level = 1 - alpha/m, var.equal = varEqual)$p.val)
  }
  else{
    return(NA)
  }
}

questionA_wilcox <- function(variable, alpha, m){
  # Filter the data was want and remove NA from variable
  dataNew <- data %>% filter(period == 2) %>% select(sex, variable) %>% na.omit
  
  # Check if the the two groups have at least one observation
  if(dim((dataNew %>% filter(sex == 'M')))[1] > 0 && dim(dataNew %>% filter(sex == 'F'))[1] > 0){
    # Wilcox p-value
    return(wilcox.test((dataNew %>% filter(sex == 'M'))[,2], (dataNew %>% filter(sex == 'F'))[,2], alternative = 'two.sided', conf.level=1-alpha/m)$p.val)
  }
  else{
    return(NA)
  }
}
```

##### b. test for the males if the mean level is the same for period 1 and period 2.
```{r}
questionB_ttest <- function(variable, alpha, m){
  # Filter the variable for males in period 1 and 2
  dataNew <- data %>% filter(sex == 'M') %>% select(period, variable) %>% na.omit

  # Check if the the two groups have at least one observation
  if(dim(dataNew %>% filter(period == 2))[1] > 0 && dim(dataNew %>% filter(period == 1))[1] > 0){
    # Calculate F-test's p-value
    pVal <- var.test((dataNew %>% filter(period == 1))[,2], (dataNew %>% filter(period == 2))[,2], conf.level = 1 - alpha, alternative = 'two.sided')$p.value
    
    # Check if the two periods have equal variances
    varEqual <- pVal > alpha
    
    # Perform the t-test
    return(t.test((dataNew %>% filter(period == 1))[,2], (dataNew %>% filter(period == 2))[,2], conf.level = 1 - alpha/m, var.equal = varEqual)$p.value)
  }
  else{
    return(NA)
  }
}

questionB_wilcox <- function(variable, alpha, m){
  # Filter the variable for males in period 1 and 2
  dataNew <- data %>% filter(sex == 'M') %>% select(period, variable) %>% na.omit
  
  # Check if the the two groups have at least one observation
  if(dim(dataNew %>% filter(period == 2))[1] > 0 && dim(dataNew %>% filter(period == 1))[1] > 0){
    # Wilcox p-value
    return(wilcox.test((dataNew %>% filter(period == 1))[,2], (dataNew %>% filter(period == 2))[,2], alternative = 'two.sided', conf.level=1-alpha/m)$p.val)
  }
  else{
    return(NA)
  }
}
```

##### c. test for the males if the mean level for period 2 is the same for the control group and the MON810 group.
```{r}
questionC_ttest <- function(variable, alpha, m){
  # Filter the data was want and remove NA from variable
  dataNew <- data %>% filter(sex == 'M') %>% filter(period == 2) %>% select(regimen, variable) %>% filter(regimen %in% c('MON810', 'control')) %>% na.omit
  
  # Check if the the two groups have at least one observation
  if(dim((dataNew %>% filter(regimen == 'control')))[1] > 0 && dim(dataNew %>% filter(regimen == 'MON810'))[1] > 0){
    # Calculate F-test's p-value
    pVal <- var.test((dataNew %>% filter(regimen == 'control'))[,2], (dataNew %>% filter(regimen == 'MON810'))[,2], conf.level = 1 - alpha, alternative = 'two.sided')$p.val
    
    # Check if the two groups have the same variance
    varEqual <- pVal > alpha
    
    # Perform the t-test
    return(t.test((dataNew %>% filter(regimen == 'control'))[,2], (dataNew %>% filter(regimen == 'MON810'))[,2], conf.level = 1 - alpha/m, var.equal = varEqual)$p.val)
  }
  else{
    return(NA)
  }
}

questionC_wilcox <- function(variable, alpha, m){
  # Filter the data was want and remove NA from variable
  dataNew <- data %>% filter(sex == 'M') %>% filter(period == 2) %>% select(regimen, variable) %>% filter(regimen %in% c('MON810', 'control')) %>% na.omit
  
  # Check if the the two groups have at least one observation
  if(dim((dataNew %>% filter(regimen == 'control')))[1] > 0 && dim(dataNew %>% filter(regimen == 'MON810'))[1] > 0){
    # Wilcox p-value
    return(wilcox.test((dataNew %>% filter(regimen == 'control'))[,2], (dataNew %>% filter(regimen == 'MON810'))[,2], alternative = 'two.sided', conf.level=1-alpha/m)$p.val)
  }
  else{
    return(NA)
  }
}
```

##### Merg data
Store the results (i.e. all the p-values) in a dataframe with one variable per row and four columns (name of the variable + three p-values). 

Non-quantitative variables: BILI, PROT, GLUCOSE, BLOOD, KETONE, UROBILI, GAMMAGT
```{r, warning = FALSE}
variable <- data  %>% select(-GLUCOSE, -BLOOD, -BILI, -PROT ,-KETONE, -UROBILI, -GAMMAGT, -id, -X, -regimen, -sex, -period) %>% colnames()

wilcox <- data.frame()
ttest <- data.frame()
for (i in 1:length(variable)){
  # Wilcox results
  wilcox <- rbind(wilcox, cbind(variable[i], questionA_wilcox(variable[i], 0.05, 1), questionB_wilcox(variable[i], 0.05, 1), questionC_wilcox(variable[i], 0.05, 1)))
  # t-test results
  ttest <- rbind(ttest, cbind(variable[i], questionA_ttest(variable[i], 0.05, 1), questionB_ttest(variable[i], 0.05, 1), questionC_ttest(variable[i], 0.05, 1)))
}

colnames(wilcox) <- c('variable', 'a', 'b', 'c')
colnames(ttest) <- c('variable', 'a', 'b', 'c')
```

Lets see which t-tests have a p-value below 0.05
```{r}
ttest$variable <- as.character(ttest$variable)
ttest$a <- as.numeric(paste(ttest$a))
ttest$b <- as.numeric(paste(ttest$b))
ttest$c <- as.numeric(paste(ttest$c))

ttest05 <- as.data.frame(cbind(ttest$variable, ttest[,2:4] < 0.05))
ttest05
```

Lets see which wilcox-tests have a p-value below 0.05
```{r}
wilcox$variable <- as.character(wilcox$variable)
wilcox$a <- as.numeric(paste(wilcox$a))
wilcox$b <- as.numeric(paste(wilcox$b))
wilcox$c <- as.numeric(paste(wilcox$c))

wilcox05 <- as.data.frame(cbind(variable, wilcox[,2:4] < 0.05))
wilcox05
```

Let us take a look at where the two tests agree and both have a `p-value < 0.05`
```{r}
as.data.frame(cbind(variable, (ttest05 == wilcox05)[,2:4]))
```

#### __(Q2)__
For each of the three tests, adjust the p-values using the Bonferroni and the Benjamini-Hochberg corrections. How can we interpret these results?

##### Bonferroni correction
Bonferroni's correction derives from that fact that the probability of identifying at least one significant result due to chance increases as more hypotheses are tested. Therefore we divide each alpha by the number of tests calculated per question. The amounts differ by question due to the different amounts of NAs in the results from trying to test sets that are uncomparable due to nonexistant observations.

$P(T_i\space\text{pass}|H_0) = \frac{\alpha}{m} $
Where `m` is the number of tests calculated for a question.

```{r}
wilcoxBonferroni <- as.data.frame(variable)
wilcoxBonferroni$`a Bonferroni` <- p.adjust(wilcox$a, method = "bonferroni", n = 60-sum(is.na(wilcox$a)))
wilcoxBonferroni$`b Bonferroni` <- p.adjust(wilcox$b, method = "bonferroni", n = 60-sum(is.na(wilcox$b)))
wilcoxBonferroni$`c Bonferroni` <- p.adjust(wilcox$c, method = "bonferroni", n = 60-sum(is.na(wilcox$c)))

ttestBonferroni <- as.data.frame(variable)
ttestBonferroni$`a Bonferroni` <- p.adjust(ttest$a, method = "bonferroni", n = 60-sum(is.na(ttest$a)))
ttestBonferroni$`b Bonferroni` <- p.adjust(ttest$b, method = "bonferroni", n = 60-sum(is.na(ttest$b)))
ttestBonferroni$`c Bonferroni` <- p.adjust(ttest$c, method = "bonferroni", n = 60-sum(is.na(ttest$c)))
```

```{r, eval=FALSE, echo=FALSE}
# TESTING ALTERNATE IMPLEMENTATION
wilcoxBonferroni2 <- data.frame()
ttestBonferroni2 <- data.frame()

for (i in 1:length(variable)){
  # Bonferroni Wilcox results
  wilcoxBonferroni2 <- rbind(wilcoxBonferroni2, cbind(variable[i], questionA_wilcox(variable[i], 0.05, 60-sum(is.na(wilcox$a))), questionB_wilcox(variable[i], 0.05, 60-sum(is.na(wilcox$b))), questionC_wilcox(variable[i], 0.05, 60-sum(is.na(wilcox$c)))))
  # Bonferroni t-test results
  ttestBonferroni2 <- rbind(ttestBonferroni2, cbind(variable[i], questionA_ttest(variable[i], 0.05, 60-sum(is.na(ttest$a))), questionB_ttest(variable[i], 0.05, 60-sum(is.na(ttest$b))), questionC_ttest(variable[i], 0.05, 60-sum(is.na(ttest$c)))))
}

colnames(wilcoxBonferroni2) <- c('variable', 'a Bonferroni', 'b Bonferroni', 'c Bonferroni')
colnames(wilcoxBonferroni2) <- c('variable', 'a Bonferroni', 'b Bonferroni', 'c Bonferroni')

View(wilcoxBonferroni2)
```


Let us see which p-values are below `0.05`.
```{r}
wilcoxBonferroni05 <- as.data.frame(cbind(variable, wilcoxBonferroni[,2:4] < 0.05))
wilcoxBonferroni05
```

With these adjustments we find that all our p-values are below `0.05` thus the __null hypothesis is rejected__ for all tests.

##### Benjamini-Hochberg correction
```{r}
wilcoxBH <- as.data.frame(variable)
wilcoxBH$`a Ben-Hoch` <- p.adjust(wilcox$a, method = "BH", n = 60-sum(is.na(wilcox$a)))
wilcoxBH$`b Ben-Hoch` <- p.adjust(wilcox$b, method = "BH", n = 60-sum(is.na(wilcox$b)))
wilcoxBH$`c Ben-Hoch` <- p.adjust(wilcox$c, method = "BH", n = 60-sum(is.na(wilcox$c)))

ttestBH <- as.data.frame(variable)
ttestBH$`a Ben-Hoch` <- p.adjust(ttest$a, method = "BH", n = 60-sum(is.na(ttest$a)))
ttestBH$`b Ben-Hoch` <- p.adjust(ttest$b, method = "BH", n = 60-sum(is.na(ttest$b)))
ttestBH$`c Ben-Hoch` <- p.adjust(ttest$c, method = "BH", n = 60-sum(is.na(ttest$c)))
```

```{r}
wilcoxBH05 <- as.data.frame(cbind(variable, wilcoxBH[,2:4] < 0.05))
wilcoxBH05
```

##### Bonferroni vs Benjamini & Hochberg

Let us check where the two corrections agree at a 5% cutoff.
```{r}
bonBH <- as.data.frame(cbind(variable, wilcoxBonferroni05[,2:4] == wilcoxBH05[,2:4]))
colnames(bonBH) <- c('variable', 'a comparison', 'b comparison', 'c comparison')
head(bonBH)
```

The table above shows where the two correction methods resulted in conflicting results at a 5% level.
```{r}
# How many conflicts in question A?
length(which(factor(bonBH$`a comparison`) == FALSE))
# B?
length(which(factor(bonBH$`b comparison`) == FALSE))
# C?
length(which(factor(bonBH$`c comparison`) == FALSE))

# A: Proportion of conflicts to the number of tests
length(which(factor(bonBH$`a comparison`) == FALSE)) / (60 - sum(is.na(bonBH$`a comparison`)))*100
# B: Proportion of conflicts to the number of tests
length(which(factor(bonBH$`b comparison`) == FALSE)) / (60 - sum(is.na(bonBH$`b comparison`)))*100
# C: Proportion of conflicts to the number of tests
length(which(factor(bonBH$`c comparison`) == FALSE)) / (60 - sum(is.na(bonBH$`c comparison`)))*100
```

They differ on question A on 7 occasions around 12% of the tests. 
They differ on question B on 7 occasions around 14% of the tests.
They do not differ on question C.

###### How can we interpret these results?

The reason we calculate the corrected p-values is because we are doing so many tests, it becomes more likely that a result is an outlier, therefore we adjust the p-value by a function of the number of tests. The new p-value then tells us whether to reject the null or alternative hypothesis from the set of tests when it is below a set threshold such as 5%.








